{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac32e18a",
   "metadata": {
    "papermill": {
     "duration": 0.004705,
     "end_time": "2024-04-17T16:45:46.966799",
     "exception": false,
     "start_time": "2024-04-17T16:45:46.962094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85094b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:45:46.978306Z",
     "iopub.status.busy": "2024-04-17T16:45:46.976977Z",
     "iopub.status.idle": "2024-04-17T16:46:00.305784Z",
     "shell.execute_reply": "2024-04-17T16:46:00.304718Z"
    },
    "papermill": {
     "duration": 13.336873,
     "end_time": "2024-04-17T16:46:00.308233",
     "exception": false,
     "start_time": "2024-04-17T16:45:46.971360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 16:45:48.880553: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-17 16:45:48.880679: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-17 16:45:49.020708: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e0581",
   "metadata": {
    "papermill": {
     "duration": 0.004334,
     "end_time": "2024-04-17T16:46:00.317200",
     "exception": false,
     "start_time": "2024-04-17T16:46:00.312866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866be7a8",
   "metadata": {
    "papermill": {
     "duration": 0.004124,
     "end_time": "2024-04-17T16:46:00.325761",
     "exception": false,
     "start_time": "2024-04-17T16:46:00.321637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Image Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0719cff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:46:00.337546Z",
     "iopub.status.busy": "2024-04-17T16:46:00.335901Z",
     "iopub.status.idle": "2024-04-17T16:46:00.779464Z",
     "shell.execute_reply": "2024-04-17T16:46:00.778376Z"
    },
    "papermill": {
     "duration": 0.452356,
     "end_time": "2024-04-17T16:46:00.782510",
     "exception": false,
     "start_time": "2024-04-17T16:46:00.330154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3115 files belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = keras.utils.image_dataset_from_directory(\n",
    "    '/kaggle/input/fruit-and-vegetable-image-recognition/train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(64, 64),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    data_format=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7947df7",
   "metadata": {
    "papermill": {
     "duration": 0.00421,
     "end_time": "2024-04-17T16:46:00.791274",
     "exception": false,
     "start_time": "2024-04-17T16:46:00.787064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Validtion Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48c50e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:46:00.801978Z",
     "iopub.status.busy": "2024-04-17T16:46:00.801595Z",
     "iopub.status.idle": "2024-04-17T16:46:00.938858Z",
     "shell.execute_reply": "2024-04-17T16:46:00.938011Z"
    },
    "papermill": {
     "duration": 0.145322,
     "end_time": "2024-04-17T16:46:00.941129",
     "exception": false,
     "start_time": "2024-04-17T16:46:00.795807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 351 files belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = keras.utils.image_dataset_from_directory(\n",
    "    '/kaggle/input/fruit-and-vegetable-image-recognition/validation',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(64, 64),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    data_format=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153975f2",
   "metadata": {
    "papermill": {
     "duration": 0.004365,
     "end_time": "2024-04-17T16:46:00.950116",
     "exception": false,
     "start_time": "2024-04-17T16:46:00.945751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4769bdec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:46:00.961368Z",
     "iopub.status.busy": "2024-04-17T16:46:00.960777Z",
     "iopub.status.idle": "2024-04-17T16:46:00.965848Z",
     "shell.execute_reply": "2024-04-17T16:46:00.965039Z"
    },
    "papermill": {
     "duration": 0.013015,
     "end_time": "2024-04-17T16:46:00.967744",
     "exception": false,
     "start_time": "2024-04-17T16:46:00.954729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3138fe5",
   "metadata": {
    "papermill": {
     "duration": 0.004281,
     "end_time": "2024-04-17T16:46:00.976568",
     "exception": false,
     "start_time": "2024-04-17T16:46:00.972287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building Convulation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5321a601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:46:00.987631Z",
     "iopub.status.busy": "2024-04-17T16:46:00.986928Z",
     "iopub.status.idle": "2024-04-17T16:46:01.028887Z",
     "shell.execute_reply": "2024-04-17T16:46:01.027492Z"
    },
    "papermill": {
     "duration": 0.050138,
     "end_time": "2024-04-17T16:46:01.031201",
     "exception": false,
     "start_time": "2024-04-17T16:46:00.981063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=[64,64,3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe2dee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:46:01.042165Z",
     "iopub.status.busy": "2024-04-17T16:46:01.041813Z",
     "iopub.status.idle": "2024-04-17T16:46:01.065363Z",
     "shell.execute_reply": "2024-04-17T16:46:01.064364Z"
    },
    "papermill": {
     "duration": 0.031868,
     "end_time": "2024-04-17T16:46:01.067803",
     "exception": false,
     "start_time": "2024-04-17T16:46:01.035935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', ))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e28e2b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:46:01.079042Z",
     "iopub.status.busy": "2024-04-17T16:46:01.078331Z",
     "iopub.status.idle": "2024-04-17T16:46:01.093271Z",
     "shell.execute_reply": "2024-04-17T16:46:01.092291Z"
    },
    "papermill": {
     "duration": 0.023356,
     "end_time": "2024-04-17T16:46:01.095867",
     "exception": false,
     "start_time": "2024-04-17T16:46:01.072511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dropout(0.5)) #to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3feac980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:46:01.107103Z",
     "iopub.status.busy": "2024-04-17T16:46:01.106751Z",
     "iopub.status.idle": "2024-04-17T16:46:01.117732Z",
     "shell.execute_reply": "2024-04-17T16:46:01.116594Z"
    },
    "papermill": {
     "duration": 0.019152,
     "end_time": "2024-04-17T16:46:01.119822",
     "exception": false,
     "start_time": "2024-04-17T16:46:01.100670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0eababd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:46:01.131393Z",
     "iopub.status.busy": "2024-04-17T16:46:01.130998Z",
     "iopub.status.idle": "2024-04-17T16:46:01.163133Z",
     "shell.execute_reply": "2024-04-17T16:46:01.161957Z"
    },
    "papermill": {
     "duration": 0.041192,
     "end_time": "2024-04-17T16:46:01.165692",
     "exception": false,
     "start_time": "2024-04-17T16:46:01.124500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c9aefc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:46:01.178011Z",
     "iopub.status.busy": "2024-04-17T16:46:01.177199Z",
     "iopub.status.idle": "2024-04-17T16:46:01.197597Z",
     "shell.execute_reply": "2024-04-17T16:46:01.196405Z"
    },
    "papermill": {
     "duration": 0.029834,
     "end_time": "2024-04-17T16:46:01.200157",
     "exception": false,
     "start_time": "2024-04-17T16:46:01.170323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49bdc3d",
   "metadata": {
    "papermill": {
     "duration": 0.004323,
     "end_time": "2024-04-17T16:46:01.209155",
     "exception": false,
     "start_time": "2024-04-17T16:46:01.204832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5365569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:46:01.219872Z",
     "iopub.status.busy": "2024-04-17T16:46:01.219480Z",
     "iopub.status.idle": "2024-04-17T16:46:01.241563Z",
     "shell.execute_reply": "2024-04-17T16:46:01.240462Z"
    },
    "papermill": {
     "duration": 0.030453,
     "end_time": "2024-04-17T16:46:01.244159",
     "exception": false,
     "start_time": "2024-04-17T16:46:01.213706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=36,activation='softmax')) "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 952827,
     "sourceId": 3173719,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.416289,
   "end_time": "2024-04-17T16:46:02.672254",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-17T16:45:44.255965",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
